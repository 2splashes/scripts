{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def kmeans(A, numCenter, numIter, N, D, init_centroids):\n",
    "    centroids = init_centroids\n",
    "\n",
    "    for l in range(numIter):\n",
    "        dist = np.array([[sqrt(np.sum((A[i,:]-centroids[j,:])**2))\n",
    "                                for j in range(numCenter)] for i in range(N)])\n",
    "        \n",
    "        labels = np.array([dist[i,:].argmin() for i in range(N)])\n",
    "\n",
    "        centroids = np.array([[np.sum(A[labels==i, j])/np.sum(labels==i)\n",
    "                                 for j in range(D)] for i in range(numCenter)])\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_centroids = X[np.random.choice(X.shape[0], size=5), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 431 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "res = kmeans(X, 5, 20, X.shape[0], X.shape[1], init_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def kmeans_numba(A, numCenter, numIter, N, D, init_centroids):\n",
    "    centroids = init_centroids\n",
    "\n",
    "    for l in range(numIter):\n",
    "        dist = np.array([[sqrt(np.sum((A[i,:] - centroids[j,:])**2))\n",
    "                                for j in range(numCenter)] for i in range(N)])\n",
    "        \n",
    "        labels = np.array([dist[i,:].argmin() for i in range(N)])\n",
    "\n",
    "        centroids = np.array([[np.sum(A[labels==i, j])/np.sum(labels==i)\n",
    "                                 for j in range(D)] for i in range(numCenter)])\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 19.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "res = kmeans_numba(X, 5, 20, X.shape[0], X.shape[1], init_centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(X, weights):\n",
    "    score = X.dot(weights)\n",
    "    proba = 1 / (1 + np.exp(-score))\n",
    "\n",
    "    return proba\n",
    "\n",
    "def logistic_regression(X, y, maxiter=1000, step_size=1e-10, \n",
    "                        l2_penalty=1, regularize=True, add_intercept=False):\n",
    "    if add_intercept:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "        \n",
    "    num_param = X.shape[1]\n",
    "\n",
    "    weights = np.zeros((num_param, 1))\n",
    "    # indicator = (y == 1)\n",
    "\n",
    "    for itr in range(maxiter):\n",
    "        pred_proba = sigmoid(X, weights)\n",
    "        errors = y.reshape(-1, 1) - pred_proba\n",
    "        gradient = X.T @ errors\n",
    "        \n",
    "        if regularize:\n",
    "            gradient[1:] -= 2 * l2_penalty * weights[1:]\n",
    "\n",
    "\n",
    "        weights = weights + step_size*gradient\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 33.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "weights = logistic_regression(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def logistic_regression_numba(X, y, maxiter, stepsize, l2_penalty, initial_weights):\n",
    "        \n",
    "    num_param = X.shape[1]\n",
    "\n",
    "    weights = initial_weights\n",
    "\n",
    "    for itr in range(maxiter):\n",
    "        score = np.dot(X, weights)\n",
    "        pred_proba = 1 / (1 + np.exp(-score))\n",
    "        errors = y - pred_proba\n",
    "        \n",
    "        gradient = np.dot(X.T, errors)\n",
    "        \n",
    "        for j in range(len(gradient), 1):\n",
    "            gradient[j] -= 2 * l2_penalty * weights[j]\n",
    "\n",
    "        weights = weights + stepsize*gradient\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 18.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "weights = logistic_regression_numba(X, y.reshape(-1, 1), maxiter=1000,\n",
    "                                                        stepsize=1e-10,\n",
    "                                                        l2_penalty=1,\n",
    "                                   initial_weights=np.zeros((X.shape[1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_parallel = numba.config.NUMBA_NUM_THREADS > 1\n",
    "\n",
    "@numba.njit(parallel=False)\n",
    "def logistic_regression_numba_improved(Y, X, w, iterations):\n",
    "    for i in range(iterations):\n",
    "        w -= np.dot(((1.0 / (1.0 + np.exp(-Y * np.dot(X,w))) - 1.0) * Y),X)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "weights = logistic_regression_numba_improved(y, X, np.zeros(X.shape[1]), 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear reg\n",
    "\n",
    "- Example from Numba\n",
    "\n",
    "Lots more at:\n",
    "\n",
    "https://github.com/numba/numba/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "X, Y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_numpy(X, Y, theta, alpha, num_iters):\n",
    "    m = Y.shape[0]\n",
    "\n",
    "    theta_x = 0.0\n",
    "    theta_y = 0.0\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        predict = theta_x + theta_y * X\n",
    "        err_x = (predict - Y)\n",
    "        err_y = (predict - Y) * X\n",
    "        theta_x = theta_x - alpha * (1.0 / m) * err_x.sum()\n",
    "        theta_y = theta_y - alpha * (1.0 / m) * err_y.sum()\n",
    "\n",
    "    theta[0] = theta_x\n",
    "    theta[1] = theta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from numba import autojit, jit, f8, int32, void\n",
    "\n",
    "@jit(void(f8[:], f8[:], f8[:], f8, int32))\n",
    "def gradient_descent_numba(X, Y, theta, alpha, num_iters):\n",
    "    m = Y.shape[0]\n",
    "\n",
    "    theta_x = 0.0\n",
    "    theta_y = 0.0\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        err_acc_x = 0.0\n",
    "        err_acc_y = 0.0\n",
    "        for j in range(X.shape[0]):\n",
    "            predict = theta_x + theta_y * X[j]\n",
    "            err_acc_x += predict - Y[j]\n",
    "            err_acc_y += (predict - Y[j]) * X[j]\n",
    "        theta_x = theta_x - alpha * (1.0 / m) * err_acc_x\n",
    "        theta_y = theta_y - alpha * (1.0 / m) * err_acc_y\n",
    "\n",
    "    theta[0] = theta_x\n",
    "    theta[1] = theta_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(gradient_descent, X, Y, iterations=10000, alpha=1e-6):\n",
    "    theta = np.empty(2, dtype=X.dtype)\n",
    "\n",
    "    ts = timer()\n",
    "    gradient_descent(X, Y, theta, alpha, iterations)\n",
    "    te = timer()\n",
    "\n",
    "    timing = te - ts\n",
    "\n",
    "    print(\"x-offset = {}    slope = {}\".format(*theta))\n",
    "    print(\"time elapsed: {} s\".format(timing))\n",
    "\n",
    "    return theta, timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------NumPy-------------\n",
      "x-offset = 0.17657380977258894    slope = 0.4927027783996578\n",
      "time elapsed: 0.16458208899985038 s\n",
      "------------Numba-------------\n",
      "x-offset = 0.176573809772589    slope = 0.4927027783996578\n",
      "time elapsed: 0.007010377999904449 s\n",
      "===========Summary============\n",
      "Numba speedup 23.5x\n"
     ]
    }
   ],
   "source": [
    "X = X[:, 1]\n",
    "print('NumPy'.center(30, '-'))\n",
    "theta_python, time_python = run(gradient_descent_numpy, X, Y)\n",
    "\n",
    "print('Numba'.center(30, '-'))\n",
    "theta_numba, time_numba  = run(gradient_descent_numba, X, Y)\n",
    "\n",
    "# make sure all method yields the same result\n",
    "assert np.allclose(theta_python, theta_numba)\n",
    "\n",
    "print('Summary'.center(30, '='))\n",
    "print('Numba speedup %.1fx' % (time_python / time_numba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
